{
    "title": "ROC Lab",
    "subtitle": "Un laboratorio para comprender la optimización en modelos de clasificación",
    "instructions_title": "Instrucciones",
    "instructions": [
        "Carga un archivo CSV con datos estructurados y selecciona la variable objetivo y las características a utilizar.",
        "Explora los datos, observa correlaciones y distribuciones.",
        "Decide cómo preparar los datos para el entrenamiento.",
        "Entrena diferentes modelos y ajusta sus parámetros para optimizar el rendimiento.",
        "Visualiza la curva ROC, ajusta el umbral y observa la matriz de confusión."
    ],
    "upload_prompt": "Carga un archivo CSV con datos estructurados",
    "file_contents": "El archivo contiene:",
    "and": "y",
    "records_loaded": "registros",
    "columns_loaded": "columnas",
    "were_loaded": "fueron cargadas", 
    "performance_help": "Ahora evalúa el rendimiento del modelo de clasificación con métricas de evaluación y visualiza la curva ROC (Receiver Operating Curve, más info: https://es.wikipedia.org/wiki/Curva_ROC). Ajusta el umbral para clasificar las predicciones como positivas o negativas y observa la matriz de confusión.",
    "about_title": "Acerca de",
    "about_text": "Experimental: Realizado para el Diplomado en Salud IA (https://didactiva.com/funsalud) con fines educativos. No para uso médico. Muchas tareas pendientes, gracias por tus comentarios y sugerencias:",
    "author": "Autor: Gustavo Ross - gross@funsalud.org.mx (2024)",
    "upload_title": "1. Carga de Datos",
    "upload_help": "Carga un archivo CSV con datos estructurados que incluyan variables numéricas para el entrenamiento de modelos de clasificación. El archivo debe incluir una columna objetivo (por ejemplo, diagnóstico, resultado) y características predictivas. Aún no se admiten datos categóricos. Más info sobre codificación de datos categóricos: https://en.wikipedia.org/wiki/Categorical_variable",
    "preview_title": "Registros Cargados",
    "select_target_column": "Selecciona la variable objetivo",
    "select_target_variable": "Selecciona la variable objetivo",
    "select_target_help": "Esta será la variable 'salida' o 'objetivo' que deseas predecir. También se conoce como el 'resultado etiquetado' o 'Y' de tus datos de entrenamiento.",
    "select_prediction_vars": "Selecciona las variables predictivas",
    "select_vars_prompt": "Selecciona las variables que deseas usar para hacer predicciones",
    "select_vars_help": "Columnas a incluir en el modelo de clasificación. Observa cómo cambian las métricas al incluir o excluir columnas.",
    "exploratory_analysis_title": "2. Análisis Exploratorio",
    "distributions_tab": "Distribuciones",
    "correlations_tab": "Correlaciones",
    "observations_tab": "Observaciones",
    "generate_observations_button": "Generar observaciones",
    "generating_observations": "Generando observaciones con pairplot...",
    "exploratory_help": "Explora los datos cargados para comprender mejor las distribuciones, correlaciones y observaciones.",
    "handle_missing": "Manejo de valores faltantes",
    "missing_help": "Selecciona cómo manejar los valores faltantes: eliminar, imputar (promedio) o ninguno.",
    "test_size_slider": "Tamaño de muestra de prueba",
    "sample_split_help": "Proporción de los datos utilizados para la prueba.",
    "num_splits_slider": "Número de particiones (GroupKFold)",
    "splits_help": "Número de particiones para la validación cruzada.",
    "training_sample_size": "% de muestras para entrenamiento/pruebas",
    "training_sample_help": "Proporción de los datos utilizados para el entrenamiento. 80% significa que apartarás 20% de las muestras para hacer pruebas del rendimiento en datos que no fueron usados en el entrenamiento.",
    "model_training_title": "4. Entrenamiento del Modelo",
    "model_training_help": "Entrena un modelo y ajusta los parámetros para un mejor rendimiento.",
    "choose_model": "Selecciona un modelo de IA",
    "choose_model_help": "Elige un modelo y ajusta los parámetros para encontrar la mejor curva ROC.",
    "performance_title": "5. Rendimiento",
    "roc_auc_curve": "Curva ROC AUC",
    "confusion_matrix": "Matriz de Confusión",
    "confusion_matrix_help": "La diagonal invertida más oscura representa menos falsos positivos/negativos. Lo que buscas es que los positivos reales sean iguales que los positivos predichos y que los negativos reales sean iguales a los negativos predichos. Dependindo de cómo establezcas el umbral, tendrás más o menos falsos positivos o falsos negativos. Determina cuál es más importante para tu aplicación.",
    "threshold_slider": "Umbral (Threshold)",
    "threshold_help": "Ajusta el umbral para una clasificación más estricta o más permisiva. Entre más alto el umbral, menos falsos positivos y más falsos negativos tendrás. Esto no influye en la curva ROC. Pero deberás sopesar si es más importante evitar falsos positivos o falsos negativos. El umbral óptimo se calcula en base a la curva ROC (es el 'codo') y representa el punto en el que se obtiene la menor combinación posible de falsos positivos y falsos negativos.",
    "stat_distributions": "Estadísticas de distribuciones:",
    "correlation_title": "Correlación entre variables:",
    "feature_importance_title": "Importancia de Características:",
    "feature_importance_help": "Visualiza la importancia de las características en el modelo.",
    "model_selection_error": "Error al seleccionar el modelo. Asegúrate de que todas las configuraciones sean correctas.",
    "metrics_error": "Error al calcular métricas de rendimiento.",
    "sensitivity_label": "Sensibilidad",
    "specificity_label": "Especificidad",
    "performance_metrics_table": "Tabla de Métricas de Rendimiento",
    "precision_label": "Precisión",
    "support_label": "Soporte",
    "dimension_mismatch_error": "Error de desajuste de dimensiones",
    "has": "tiene",
    "but": "pero",
    "error": "Ocurrió un error",
    "hyperparameters": "Ajusta los hiperparámetros:",
    "data_preparation_title": "3. Preparación de Datos",
    "data_preparation_help": "Prepara tus datos para el entrenamiento del modelo seleccionando cómo manejar los valores faltantes y normalizar las características.",
    "no_missing_values": "No hay valores faltantes en el conjunto de datos.",
    "no_missing_help": "Todos los valores están presentes; no se requiere ninguna acción. Si tuvieras datos faltantes en algunas columnas, podrías eliminar las filas con valores faltantes, imputar los valores faltantes (por ejemplo con la media de la columna) o no hacer nada.",
    "normalize_values": "Normalizar valores",
    "normalize_help": "Normaliza los datos antes de entrenar el modelo para que todos estén en la misma escala. Más info: https://es.wikipedia.org/wiki/Normalizaci%C3%B3n_(estad%C3%ADstica)",
    "lasso_regularization": "Regularización Lasso (previene el sobreajuste)",
    "lasso_help": "Aplica la regularización Lasso para prevenir el sobreajuste. Más info: https://es.wikipedia.org/wiki/LASSO_(estad%C3%ADstica)",
    "remove_outliers": "Eliminar Outliers (Valores Atípicos)",
    "remove_outliers_help": "Detectar y eliminar outliers o valores atípicos del conjunto de datos. Más info: https://es.wikipedia.org/wiki/Valor_at%C3%ADpico",
    "sample_splitting": "División de Muestras",
    "sample_splitting_help": "Determina cómo dividir tus datos en conjuntos de entrenamiento y prueba.",
    "test_sample_size": "Tamaño de Muestra de Prueba",
    "test_sample_help": "Establece la proporción de datos que se utilizarán para la prueba.",
    "sample_counts": "Muestras",
    "num_partitions": "Número de particiones o grupos K-Fold",
    "num_partitions_help": "Establece el número de particiones para la validación cruzada. Los datos se dividen en grupos de tamaño igual y se utilizan para entrenamiento y prueba para promediar los resultados obtenidos en diferentes subgrupos. Esto aumenta la confiabilidad de que el modelo se comporte igual en un entorno de producción/real.",
    "logistic_regression_desc": "La regresión logística es un modelo estadístico que utiliza una función logística para modelar una variable dependiente binaria. [Más información](https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica)",
    "knn_desc": "K-Nearest Neighbors es un algoritmo simple basado en instancias que clasifica según la clase mayoritaria entre los K vecinos más cercanos. [Más información](https://es.wikipedia.org/wiki/K_vecinos_m%C3%A1s_cercanos)",
    "knn_neighbors": "Número de Vecinos",
    "knn_neighbors_help": "El número de vecinos a considerar al clasificar una nueva instancia.",
    "naive_bayes_desc": "Naive Bayes es una familia de algoritmos probabilísticos basados en el teorema de Bayes, asumiendo independencia entre características. [Más información](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo)",
    "naive_bayes_no_hyperparameters": "No hay hiperparámetros para ajustar en Naive Bayes.",
    "svm_desc": "Las Máquinas de Vectores de Soporte son modelos de aprendizaje supervisado utilizados para análisis de clasificación y regresión. [Más información](https://es.wikipedia.org/wiki/M%C3%A1quina_de_vectores_de_soporte)",
    "svm_c": "Parámetro de Regularización (C)",
    "svm_c_help": "La fuerza de la regularización. Los valores más pequeños especifican una regularización más fuerte.",
    "svm_kernel": "Kernel",
    "decision_tree_desc": "Los Árboles de Decisión son un método de aprendizaje supervisado no paramétrico utilizado para clasificación y regresión. [Más información](https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n)",
    "tree_desc": "El árbol es un clasificador de árbol de decisiones que divide los datos en subconjuntos basados en el valor de una característica.",
    "tree_depth": "Profundidad del Árbol",
    "tree_depth_help": "La profundidad máxima del árbol.",
    "random_forest_desc": "Random Forest es un método de conjunto que utiliza múltiples árboles de decisión para mejorar la precisión y controlar el sobreajuste. [Más información](https://es.wikipedia.org/wiki/Random_forest)",
    "rf_estimators": "Número de Estimadores",
    "rf_estimators_help": "El número de árboles en el bosque.",
    "xgboost_desc": "XGBoost es una biblioteca de optimización de gradient boosting diseñada para ser altamente eficiente, flexible y portátil. [Más información](https://es.wikipedia.org/wiki/XGBoost)",
    "xgb_learning_rate": "Tasa de Aprendizaje",
    "xgb_learning_rate_help": "El tamaño del paso de reducción utilizado para prevenir el sobreajuste.",
    "xgb_estimators": "Número de Estimadores",
    "xgb_estimators_help": "El número de rondas de boosting.",
    "gradient_boosting_desc": "Gradient Boosting es una técnica de conjunto que construye modelos secuencialmente, corrigiendo los errores de los modelos anteriores. [Más información](https://es.wikipedia.org/wiki/Gradient_boosting)",
    "adaboost_desc": "AdaBoost, o Boosting Adaptativo, combina múltiples clasificadores débiles para crear un clasificador fuerte. [Más información](https://es.wikipedia.org/wiki/Boosting)",
    "adaboost_estimators": "Número de Estimadores",
    "adaboost_estimators_help": "El número máximo de estimadores en el que se termina el boosting.",
    "lightgbm_desc": "LightGBM es un marco de gradient boosting que utiliza algoritmos de aprendizaje basados en árboles, diseñado para entrenamiento distribuido y eficiente. [Más información](https://en.wikipedia.org/wiki/LightGBM)",
    "importance": "Importancia",
    "training": "Entrenamiento",
    "select_model": "Selecciona un modelo",
    "select_model_help": "Intenta seleccionar diferentes modelos para ver cómo se desempeñan en tu conjunto de datos. Ajusta los hiperparámetros para optimizar el rendimiento.",
    "logreg_c": "Inverso de la fuerza de regularización (C)",
    "logreg_c_help": "Los valores más pequeños especifican una regularización más fuerte.",
    "roc_curve": "Curva ROC",
    "fpr_label": "1-Especificidad",
    "tpr_label": "Sensibilidad",
    "predicted_label": "Predicción",
    "actual_label": "Real",
    "performance_metrics_help": "1. **Precisión**: La precisión es la proporción de verdaderos positivos sobre el total de predicciones positivas. Indica cuántas de las instancias clasificadas como positivas realmente lo son.  \n**Fórmula**:  \n\\[\\text{Precisión} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}}\\]  \n**Interpretación**: Una precisión alta significa que hay pocos falsos positivos. Es especialmente importante en situaciones donde el costo de una falsa alarma es alto.  \n\n2. **Sensibilidad**: La sensibilidad, también conocida como recall, es la proporción de verdaderos positivos sobre el total de instancias que son realmente positivas. Mide la capacidad del modelo para identificar todas las instancias positivas.  \n**Fórmula**:  \n\\[\\text{Sensibilidad} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}}\\]  \n**Interpretación**: Una alta sensibilidad indica que el modelo tiene un buen desempeño en la detección de casos positivos. Es crucial en situaciones donde es vital no perder casos positivos, como en diagnósticos médicos.  \n\n3. **F1-Score**: El F1-score es la media armónica entre la precisión y la sensibilidad. Combina ambas métricas para ofrecer una visión general del rendimiento del modelo, especialmente en situaciones donde hay un desbalance entre las clases.  \n**Fórmula**:  \n\\[\\text{F1} = 2 \\times \\frac{\\text{Precisión} \\times \\text{Sensibilidad}}{\\text{Precisión} + \\text{Sensibilidad}}\\]  \n**Interpretación**: Un F1-score alto indica que el modelo tiene tanto una buena precisión como una buena sensibilidad. Es útil en casos donde se desea un equilibrio entre ambas.  \n\n4. **Soporte**: El soporte se refiere al número de instancias reales en cada clase. Proporciona contexto sobre cuántas muestras se están considerando para cada métrica.  \n**Interpretación**: Ayuda a entender la distribución de clases en los datos y puede influir en la interpretación de otras métricas. Si una clase tiene un bajo soporte, puede no ser un buen indicador de rendimiento general.  \n\n5. **Exactitud**: La exactitud es la proporción de todas las predicciones correctas (verdaderos positivos y verdaderos negativos) sobre el total de instancias.  \n**Fórmula**:  \n\\[\\text{Exactitud} = \\frac{\\text{Verdaderos Positivos} + \\text{Verdaderos Negativos}}{\\text{Total de Instancias}}\\]  \n**Interpretación**: Aunque la exactitud es fácil de entender, puede ser engañosa en conjuntos de datos desbalanceados. No es la mejor métrica para usar cuando hay una gran discrepancia entre las clases.  \n\n6. **Promedio Macro**: El promedio macro calcula la métrica (precisión, sensibilidad, etc.) para cada clase por separado y luego toma la media. No tiene en cuenta el soporte.  \n**Interpretación**: Es útil para entender el rendimiento general del modelo en todas las clases, dándole la misma importancia a cada clase independientemente de su tamaño.  \n\n7. **Promedio Ponderado**: El promedio ponderado también calcula la métrica para cada clase, pero toma en cuenta el soporte al calcular la media.  \n**Interpretación**: Es útil para obtener un rendimiento general del modelo que refleje el tamaño de cada clase, dándole más peso a las clases que tienen más instancias.  \n\n### Resumen  \nEstas métricas proporcionan una visión completa del rendimiento del modelo de clasificación. Al evaluar el rendimiento, es importante considerar no solo la exactitud, sino también la precisión y la sensibilidad, especialmente en contextos críticos como la salud, donde los falsos positivos y negativos pueden tener consecuencias significativas.",
    "testing": "Prueba"
}
