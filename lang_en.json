{
    "title": "ROC Curve Lab",
    "subtitle": "A lab for understanding optimization in classification models",
    "instructions_title": "Instructions",
    "instructions": [
        "Upload a CSV file with structured data and select the target variable and features to use.",
        "Explore the data, observe correlations, and distributions.",
        "Decide how to prepare the data for training.",
        "Train different models and adjust their parameters to optimize performance.",
        "Visualize the ROC curve, adjust the threshold, and observe the confusion matrix."
    ],
    "upload_prompt": "Upload a CSV file with structured data",
    "file_contents": "The file contains:",
    "and": "and",
    "records_loaded": "records",
    "columns_loaded": "columns",
    "were_loaded": "were loaded",
    "performance_help": "Evaluate the performance of the classification model with evaluation metrics and visualize the ROC curve. Adjust the threshold to classify predictions as positive or negative and observe the confusion matrix.",
    "about_title": "About",
    "about_text": "ROC Lab is a laboratory for optimizing classification models. Sometimes we have datasets that we are unsure about their conclusiveness and want to quickly determine if there is any trainable information in them. Upload your data, explore distributions and correlations, train different models, and adjust their hyperparameters to optimize performance. Visualize the ROC curve, adjust the threshold, and observe the confusion matrix to evaluate model performance.",
    "author": "Want to contribute improvements or suggestions? Contact the author: Gustavo Ross - gross@funsalud.org.mx (2024)",
    "upload_title": "1. Data Upload",
    "upload_help": "Upload a CSV or Excel file with structured data that includes numerical and categorical variables for training classification models. The system automatically detects data types and applies appropriate preprocessing for each variable type. The file must include a target column (e.g., diagnosis, outcome) and predictive features.",
    "preview_title": "Records Loaded",
    "select_target_column": "Select the target variable",
    "select_target_variable": "Select the target variable",
    "select_target_help": "This will be the 'output' or 'target' variable you want to predict. It is also known as the 'labeled outcome' or 'Y' from your training data.",
    "select_prediction_vars": "Select the predictive variables",
    "select_vars_prompt": "Select the variables you want to use to make predictions",
    "select_vars_help": "Columns to include in the classification model. Observe how metrics change when including or excluding columns.",
    "exploratory_analysis_title": "2. Exploratory Analysis",
    "distributions_tab": "Distributions",
    "correlations_tab": "Correlations",
    "observations_tab": "Observations",
    "generate_observations_button": "Generate observations",
    "generating_observations": "Generating observations with pairplot...",
    "exploratory_help": "Explore the uploaded data to better understand distributions, correlations, and observations.",
    "handle_missing": "Handling missing values",
    "missing_help": "Select how to handle missing values: drop, impute (mean), or none.",
    "normalize_help": "Normalize the data before training the model.",
    "test_size_slider": "Test sample size",
    "sample_split_help": "Proportion of the data used for testing.",
    "num_splits_slider": "Number of partitions (GroupKFold)",
    "splits_help": "Number of partitions for cross-validation.",
    "training_sample_size": "Training sample size",
    "training_sample_help": "Proportion of the data used for training.",
    "model_training_title": "4. Model Training",
    "model_training_help": "Train a model and adjust parameters for better performance.",
    "choose_model": "Select an AI model",
    "choose_model_help": "Choose a model and adjust parameters to find the best ROC curve.",
    "performance_title": "5. Performance",
    "roc_auc_curve": "ROC AUC Curve",
    "confusion_matrix": "Confusion Matrix",
    "confusion_matrix_help": "The darker diagonal represents fewer false positives/negatives.",
    "threshold_slider": "Threshold (optimal: {optimal_threshold})",
    "threshold_help": "Adjust the threshold for stricter or more permissive classification.",
    "stat_distributions": "Statistics of distributions:",
    "correlation_title": "Correlation between variables:",
    "feature_importance_title": "Feature Importance:",
    "feature_importance_help": "Visualize the importance of features in the model.",
    "model_selection_error": "Error selecting the model. Ensure all configurations are correct.",
    "metrics_error": "Error calculating performance metrics.",
    "sensitivity_label": "Sensitivity",
    "specificity_label": "Specificity",
    "performance_metrics_table": "Performance Metrics Table",
    "precision_label": "Precision",
    "support_label": "Support",
    "dimension_mismatch_error": "Dimension mismatch error",
    "has": "has",
    "but": "but",
    "error": "An error occurred",
    "hyperparameters": "Adjust hyperparameters:",
    "data_preparation_title": "Data Preparation",
    "data_preparation_help": "Prepare your data for model training by selecting how to handle missing values and normalize the features.",
    "no_missing_values": "No missing values in the dataset.",
    "no_missing_help": "All values are present; no action required.",
    "normalize_values": "Normalize values",
    "normalize_help": "Normalize the feature values to bring them into a standard scale.",
    "lasso_regularization": "Lasso Regularization",
    "lasso_help": "Apply Lasso regularization to prevent overfitting.",
    "remove_outliers": "Remove Outliers",
    "remove_outliers_help": "Detect and remove outliers from the dataset.",
    "sample_splitting": "Sample Splitting",
    "sample_splitting_help": "Determine how to split your data into training and testing sets.",
    "test_sample_size": "Test Sample Size",
    "test_sample_help": "Set the proportion of data to be used for testing.",
    "sample_counts": "Sample Counts",
    "num_partitions": "Number of K-Fold Group partitions",
    "num_partitions_help": "Set the number of partitions for cross-validation. K-Fold Group splits the data into K groups and then uses each group as a test set to improve model accuracy.",
    "logistic_regression_desc": "Logistic regression is a statistical model that uses a logistic function to model a binary dependent variable. [More information](https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica)",
    "knn_desc": "K-Nearest Neighbors is a simple instance-based learning algorithm that classifies based on the majority class among the K nearest neighbors. [More information](https://es.wikipedia.org/wiki/K_vecinos_m%C3%A1s_cercanos)",
    "knn_neighbors": "Number of Neighbors",
    "knn_neighbors_help": "The number of neighbors to consider when classifying a new instance.",
    "naive_bayes_desc": "Naive Bayes is a family of probabilistic algorithms based on Bayes' theorem, assuming independence between features. [More information](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo)",
    "naive_bayes_no_hyperparameters": "No hyperparameters to adjust for Naive Bayes.",
    "svm_desc": "Support Vector Machines are supervised learning models used for classification and regression analysis. [More information](https://es.wikipedia.org/wiki/M%C3%A1quina_de_vectores_de_soporte)",
    "svm_c": "Regularization Parameter (C)",
    "svm_c_help": "The strength of the regularization. Smaller values specify stronger regularization.",
    "svm_kernel": "Kernel",
    "decision_tree_desc": "Decision Trees are a non-parametric supervised learning method used for classification and regression. [More information](https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n)",
    "tree_desc": "The tree is a decision tree classifier that splits the data into subsets based on the value of a feature.",
    "tree_depth": "Tree Depth",
    "tree_depth_help": "The maximum depth of the tree.",
    "random_forest_desc": "Random Forest is an ensemble method that uses multiple decision trees to improve accuracy and control overfitting. [More information](https://es.wikipedia.org/wiki/Random_forest)",
    "rf_estimators": "Number of Estimators",
    "rf_estimators_help": "The number of trees in the forest.",
    "xgboost_desc": "XGBoost is an optimized gradient boosting library designed to be highly efficient, flexible, and portable. [More information](https://es.wikipedia.org/wiki/XGBoost)",
    "xgb_learning_rate": "Learning Rate",
    "xgb_learning_rate_help": "The step size shrinkage used to prevent overfitting.",
    "xgb_estimators": "Number of Estimators",
    "xgb_estimators_help": "The number of boosting rounds.",
    "gradient_boosting_desc": "Gradient Boosting is an ensemble technique that builds models sequentially, correcting the errors of previous models. [More information](https://es.wikipedia.org/wiki/Gradient_boosting)",
    "adaboost_desc": "AdaBoost, or Adaptive Boosting, combines multiple weak classifiers to create a strong classifier. [More information](https://es.wikipedia.org/wiki/Boosting)",
    "adaboost_estimators": "Number of Estimators",
    "adaboost_estimators_help": "The maximum number of estimators at which boosting is terminated.",
    "lightgbm_desc": "LightGBM is a gradient boosting framework that uses tree-based learning algorithms, designed for distributed and efficient training. [More information](https://en.wikipedia.org/wiki/LightGBM)",
    "importance": "Importance",
    "training": "Training",
    "select_model": "Select a model",
    "select_model_help": "Try selecting different models to see how they perform on your dataset. Adjust the hyperparameters to optimize performance.",
    "logreg_c": "Inverse of regularization strength (C)",
    "logreg_c_help": "Smaller values specify stronger regularization.",
    "roc_curve": "ROC Curve",
    "fpr_label": "False Positive Rate",
    "tpr_label": "True Positive Rate",
    "predicted_label": "Predicted",
    "actual_label": "Actual",
    "performance_metrics_help": "Performance Metrics",
    "testing": "Testing",
    "footer": "This software is open under the GNU General Public License, version 3. You may redistribute and/or modify it under the terms of this license. This software is provided 'as-is' without any warranty of any kind. See the GNU General Public License for more details. You can access the source code [here](https://github.com/mcquaas/ROClab) or request it by contacting Gustavo directly: gross@funsalud.org.mx.",
    "license_title": "Licensed under GNU GPL v3",
    "show_license": "Show GPL v3 License",
    
    "numeric_cols": "Numeric columns",
    "binary_cols": "Binary columns",
    "categorical_cols": "Categorical columns",
    "date_cols": "Date columns",
    "text_cols": "Text columns",
    "data_info": "Data information",
    "rows": "Rows",
    "columns": "Columns",
    "selected_numeric": "Selected numeric features",
    "selected_categorical": "Selected categorical features",
    "classification_problem": "Classification problem with classes",
    "regression_problem": "Regression problem",
    "auto_preprocessing": "Automatic preprocessing",
    "auto_preprocessing_help": "Automatically apply optimal preprocessing based on the selected model",
    "preprocessing_tips": "Preprocessing tips",
    "preprocessing_applied": "Preprocessing applied:",
    "normalized_data": "Data automatically normalized",
    "imputed_missing": "Missing values imputed",
    "knn_large_warning": "Warning: Large number of samples may slow down KNN",
    "trees_handle_missing": "Trees handle missing values internally",
    "manual_normalization": "Manual normalization applied",
    "encoded_column": "Column encoded",
    "column_removed": "Column removed due to encoding issues",
    "yes_no_conversion_error": "Error occurred when converting 'YES' to float",
    "yes_no_conversion_fixed": "The values 'YES'/'NO' have been converted to numeric values",
    "conversion_required": "It is necessary to convert categorical values (like 'YES'/'NO', 'F'/'M') to numeric format",
    "columns_processed": "columns processed"
}
